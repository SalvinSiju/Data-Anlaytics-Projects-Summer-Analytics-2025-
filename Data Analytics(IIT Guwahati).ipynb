{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPNEfk7B0aap5sQIXZd2NxH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["import pandas as pd\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.pipeline import Pipeline\n","from sklearn.compose import ColumnTransformer\n","\n","# Load datasets\n","train_df = pd.read_csv(\"hacktrain.csv\")\n","test_df = pd.read_csv(\"hacktest.csv\")\n","\n","# Drop unnecessary column if present\n","if \"Unnamed: 0\" in train_df.columns:\n","    train_df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n","if \"Unnamed: 0\" in test_df.columns:\n","    test_df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n","\n","# Extract features and target\n","X = train_df.drop(columns=[\"ID\", \"class\"])\n","y = train_df[\"class\"]\n","X_test = test_df.drop(columns=[\"ID\"])\n","test_ids = test_df[\"ID\"]\n","\n","# Preprocessing pipeline\n","numeric_features = X.columns.tolist()\n","preprocessor = ColumnTransformer(transformers=[\n","    ('num', Pipeline(steps=[\n","        ('imputer', SimpleImputer(strategy='mean')),\n","        ('scaler', StandardScaler())\n","    ]), numeric_features)\n","])\n","\n","# Complete pipeline with logistic regression\n","pipeline = Pipeline(steps=[\n","    ('preprocessor', preprocessor),\n","    ('classifier', LogisticRegression(max_iter=1000, multi_class='multinomial', solver='lbfgs'))\n","])\n","\n","# Fit the model\n","pipeline.fit(X, y)\n","\n","# Predict test data\n","preds = pipeline.predict(X_test)\n","\n","# Create submission DataFrame\n","submission = pd.DataFrame({\n","    'ID': test_ids,\n","    'class': preds\n","})\n","\n","# Save to CSV\n","submission.to_csv(\"submission.csv\", index=False)\n","print(\"Submission saved as submission.csv\")"],"metadata":{"id":"t0wJlMiOL_LA"}},{"cell_type":"code","source":["import pandas as pd\n","import gdown\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.pipeline import Pipeline\n","from sklearn.compose import ColumnTransformer\n","\n","# Load datasets\n","train_url = 'https://drive.google.com/uc?id=1tKyMi7ERS8lkRr0BSRMYJn3tv3ryLtT3'\n","test_url = 'https://drive.google.com/uc?id=1Pd9a30DXPZHgSSzv2y5Hsc44A5oElxKV'\n","\n","gdown.download(train_url, 'hacktrain.csv', quiet=False)\n","gdown.download(test_url, 'hacktest.csv', quiet=False)\n","\n","train_df = pd.read_csv('hacktrain.csv')\n","test_df = pd.read_csv('hacktest.csv')\n","\n","# Drop unnecessary column if present\n","if \"Unnamed: 0\" in train_df.columns:\n","    train_df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n","if \"Unnamed: 0\" in test_df.columns:\n","    test_df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n","\n","# Extract features and target\n","X = train_df.drop(columns=[\"ID\", \"class\"])\n","y = train_df[\"class\"]\n","X_test = test_df.drop(columns=[\"ID\"])\n","test_ids = test_df[\"ID\"]\n","\n","# Preprocessing pipeline\n","numeric_features = X.columns.tolist()\n","preprocessor = ColumnTransformer(transformers=[\n","    ('num', Pipeline(steps=[\n","        ('imputer', SimpleImputer(strategy='mean')),\n","        ('scaler', StandardScaler())\n","    ]), numeric_features)\n","])\n","\n","# Complete pipeline with logistic regression\n","pipeline = Pipeline(steps=[\n","    ('preprocessor', preprocessor),\n","    ('classifier', LogisticRegression(max_iter=1000, multi_class='multinomial', solver='lbfgs'))\n","])\n","\n","# Fit the model\n","pipeline.fit(X, y)\n","\n","# Predict test data\n","preds = pipeline.predict(X_test)\n","\n","# Create submission DataFrame\n","submission = pd.DataFrame({\n","    'ID': test_ids,\n","    'class': preds\n","})\n","\n","# Save to CSV\n","submission.to_csv(\"submission.csv\", index=False)\n","print(\"Submission saved as submission.csv\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l41UheMjwe2O","executionInfo":{"status":"ok","timestamp":1749625020895,"user_tz":-330,"elapsed":8358,"user":{"displayName":"Salvin Siju","userId":"12323725506983597856"}},"outputId":"fc00471d-b4a0-4bc7-eec9-7a049bf2a683"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading...\n","From: https://drive.google.com/uc?id=1tKyMi7ERS8lkRr0BSRMYJn3tv3ryLtT3\n","To: /content/hacktrain.csv\n","100%|██████████| 1.67M/1.67M [00:00<00:00, 145MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1Pd9a30DXPZHgSSzv2y5Hsc44A5oElxKV\n","To: /content/hacktest.csv\n","100%|██████████| 634k/634k [00:00<00:00, 96.9MB/s]\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Submission saved as submission.csv\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import gdown\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import StandardScaler, PolynomialFeatures, RobustScaler\n","from sklearn.pipeline import Pipeline\n","from sklearn.compose import ColumnTransformer\n","from sklearn.model_selection import GridSearchCV, cross_val_score\n","from sklearn.feature_selection import SelectKBest, f_classif, RFE\n","from sklearn.metrics import classification_report, accuracy_score\n","\n","# Load datasets\n","train_url = 'https://drive.google.com/uc?id=1tKyMi7ERS8lkRr0BSRMYJn3tv3ryLtT3'\n","test_url = 'https://drive.google.com/uc?id=1Pd9a30DXPZHgSSzv2y5Hsc44A5oElxKV'\n","\n","gdown.download(train_url, 'hacktrain.csv', quiet=False)\n","gdown.download(test_url, 'hacktest.csv', quiet=False)\n","\n","train_df = pd.read_csv('hacktrain.csv')\n","test_df = pd.read_csv('hacktest.csv')\n","\n","# Drop unnecessary column if present\n","if \"Unnamed: 0\" in train_df.columns:\n","    train_df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n","if \"Unnamed: 0\" in test_df.columns:\n","    test_df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n","\n","# Extract features and target\n","X = train_df.drop(columns=[\"ID\", \"class\"])\n","y = train_df[\"class\"]\n","X_test = test_df.drop(columns=[\"ID\"])\n","test_ids = test_df[\"ID\"]\n","\n","print(f\"Training data shape: {X.shape}\")\n","print(f\"Test data shape: {X_test.shape}\")\n","print(f\"Target classes: {y.unique()}\")\n","\n","# METHOD 1: Enhanced Preprocessing with Robust Scaling and Polynomial Features\n","print(\"\\n=== METHOD 1: Enhanced Preprocessing ===\")\n","\n","numeric_features = X.columns.tolist()\n","\n","# Use RobustScaler instead of StandardScaler (less sensitive to outliers)\n","enhanced_preprocessor = ColumnTransformer(transformers=[\n","    ('num', Pipeline(steps=[\n","        ('imputer', SimpleImputer(strategy='median')),  # median often better than mean\n","        ('poly', PolynomialFeatures(degree=2, include_bias=False, interaction_only=True)),\n","        ('scaler', RobustScaler())\n","    ]), numeric_features)\n","])\n","\n","enhanced_pipeline = Pipeline(steps=[\n","    ('preprocessor', enhanced_preprocessor),\n","    ('classifier', LogisticRegression(max_iter=2000, multi_class='multinomial', solver='lbfgs'))\n","])\n","\n","enhanced_pipeline.fit(X, y)\n","enhanced_preds = enhanced_pipeline.predict(X_test)\n","\n","# METHOD 2: Hyperparameter Tuning with GridSearchCV\n","print(\"\\n=== METHOD 2: Hyperparameter Tuning ===\")\n","\n","basic_preprocessor = ColumnTransformer(transformers=[\n","    ('num', Pipeline(steps=[\n","        ('imputer', SimpleImputer(strategy='mean')),\n","        ('scaler', StandardScaler())\n","    ]), numeric_features)\n","])\n","\n","# Define parameter grid\n","param_grid = {\n","    'classifier__C': [0.01, 0.1, 1, 10, 100],\n","    'classifier__penalty': ['l1', 'l2', 'elasticnet'],\n","    'classifier__solver': ['liblinear', 'saga'],\n","    'classifier__max_iter': [1000, 2000]\n","}\n","\n","# Create pipeline for grid search\n","grid_pipeline = Pipeline(steps=[\n","    ('preprocessor', basic_preprocessor),\n","    ('classifier', LogisticRegression(multi_class='multinomial'))\n","])\n","\n","# Perform grid search\n","grid_search = GridSearchCV(\n","    grid_pipeline,\n","    param_grid,\n","    cv=5,\n","    scoring='accuracy',\n","    n_jobs=-1,\n","    verbose=1\n",")\n","\n","grid_search.fit(X, y)\n","print(f\"Best parameters: {grid_search.best_params_}\")\n","print(f\"Best cross-validation score: {grid_search.best_score_:.4f}\")\n","\n","tuned_preds = grid_search.predict(X_test)\n","\n","# METHOD 3: Feature Selection with Logistic Regression\n","print(\"\\n=== METHOD 3: Feature Selection ===\")\n","\n","# Using SelectKBest for feature selection\n","feature_selector = SelectKBest(score_func=f_classif, k='all')  # Start with all, then optimize k\n","\n","fs_preprocessor = ColumnTransformer(transformers=[\n","    ('num', Pipeline(steps=[\n","        ('imputer', SimpleImputer(strategy='mean')),\n","        ('scaler', StandardScaler()),\n","        ('selector', feature_selector)\n","    ]), numeric_features)\n","])\n","\n","# Try different numbers of features\n","best_score = 0\n","best_k = None\n","k_values = [int(len(numeric_features) * ratio) for ratio in [0.5, 0.7, 0.8, 0.9, 1.0]]\n","\n","for k in k_values:\n","    fs_preprocessor.named_transformers_['num'].named_steps['selector'].k = k\n","\n","    fs_pipeline = Pipeline(steps=[\n","        ('preprocessor', fs_preprocessor),\n","        ('classifier', LogisticRegression(max_iter=1000, multi_class='multinomial', solver='lbfgs'))\n","    ])\n","\n","    # Cross-validation score\n","    cv_scores = cross_val_score(fs_pipeline, X, y, cv=5, scoring='accuracy')\n","    mean_score = cv_scores.mean()\n","\n","    print(f\"k={k}: CV accuracy = {mean_score:.4f} (+/- {cv_scores.std() * 2:.4f})\")\n","\n","    if mean_score > best_score:\n","        best_score = mean_score\n","        best_k = k\n","\n","print(f\"Best k: {best_k}\")\n","\n","# Train with best k\n","fs_preprocessor.named_transformers_['num'].named_steps['selector'].k = best_k\n","fs_pipeline = Pipeline(steps=[\n","    ('preprocessor', fs_preprocessor),\n","    ('classifier', LogisticRegression(max_iter=1000, multi_class='multinomial', solver='lbfgs'))\n","])\n","\n","fs_pipeline.fit(X, y)\n","fs_preds = fs_pipeline.predict(X_test)\n","\n","# METHOD 4: Recursive Feature Elimination\n","print(\"\\n=== METHOD 4: Recursive Feature Elimination ===\")\n","\n","rfe_preprocessor = ColumnTransformer(transformers=[\n","    ('num', Pipeline(steps=[\n","        ('imputer', SimpleImputer(strategy='mean')),\n","        ('scaler', StandardScaler())\n","    ]), numeric_features)\n","])\n","\n","# First fit preprocessor to get feature names\n","rfe_preprocessor.fit(X)\n","X_preprocessed = rfe_preprocessor.transform(X)\n","\n","# Apply RFE\n","estimator = LogisticRegression(max_iter=1000, multi_class='multinomial', solver='lbfgs')\n","rfe = RFE(estimator, n_features_to_select=best_k if best_k else len(numeric_features)//2)\n","rfe.fit(X_preprocessed, y)\n","\n","print(f\"Selected {rfe.n_features_} features out of {X_preprocessed.shape[1]}\")\n","\n","# Create final RFE pipeline\n","rfe_pipeline = Pipeline(steps=[\n","    ('preprocessor', rfe_preprocessor),\n","    ('selector', rfe),\n","    ('classifier', LogisticRegression(max_iter=1000, multi_class='multinomial', solver='lbfgs'))\n","])\n","\n","rfe_pipeline.fit(X, y)\n","rfe_preds = rfe_pipeline.predict(X_test)\n","\n","# METHOD 5: Ensemble of Different Configurations\n","print(\"\\n=== METHOD 5: Ensemble Approach ===\")\n","\n","# Combine predictions from different methods using majority voting\n","from scipy import stats\n","\n","# Stack all predictions\n","all_predictions = np.column_stack([\n","    enhanced_preds,\n","    tuned_preds,\n","    fs_preds,\n","    rfe_preds\n","])\n","\n","# Majority vote for each sample\n","ensemble_preds = []\n","for i in range(len(all_predictions)):\n","    mode_result = stats.mode(all_predictions[i], keepdims=True)\n","    ensemble_preds.append(mode_result.mode[0])\n","\n","ensemble_preds = np.array(ensemble_preds)\n","\n","# METHOD 6: Class Weight Balancing\n","print(\"\\n=== METHOD 6: Class Weight Balancing ===\")\n","\n","# Check class distribution\n","print(f\"Class distribution: {y.value_counts().to_dict()}\")\n","\n","balanced_pipeline = Pipeline(steps=[\n","    ('preprocessor', basic_preprocessor),\n","    ('classifier', LogisticRegression(\n","        max_iter=2000,\n","        multi_class='multinomial',\n","        solver='lbfgs',\n","        class_weight='balanced'  # Automatically balance classes\n","    ))\n","])\n","\n","balanced_pipeline.fit(X, y)\n","balanced_preds = balanced_pipeline.predict(X_test)\n","\n","# Create submissions for all methods\n","methods = {\n","    'enhanced': enhanced_preds,\n","    'tuned': tuned_preds,\n","    'feature_selected': fs_preds,\n","    'rfe': rfe_preds,\n","    'ensemble': ensemble_preds,\n","    'balanced': balanced_preds\n","}\n","\n","for method_name, preds in methods.items():\n","    submission = pd.DataFrame({\n","        'ID': test_ids,\n","        'class': preds\n","    })\n","    submission.to_csv(f\"submission_{method_name}.csv\", index=False)\n","    print(f\"Submission saved as submission_{method_name}.csv\")\n","\n","print(\"\\n=== Cross-Validation Scores Comparison ===\")\n","pipelines = {\n","    'Enhanced': enhanced_pipeline,\n","    'Feature Selected': fs_pipeline,\n","    'RFE': rfe_pipeline,\n","    'Balanced': balanced_pipeline\n","}\n","\n","for name, pipeline in pipelines.items():\n","    cv_scores = cross_val_score(pipeline, X, y, cv=5, scoring='accuracy')\n","    print(f\"{name}: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n","\n","print(\"\\nRecommendation: Try the ensemble approach first, then compare with individual methods!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"AQLjAn1uzN0n","executionInfo":{"status":"error","timestamp":1749625573248,"user_tz":-330,"elapsed":171765,"user":{"displayName":"Salvin Siju","userId":"12323725506983597856"}},"outputId":"fca54411-eaf9-491e-ae0b-f3b30f787209"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading...\n","From: https://drive.google.com/uc?id=1tKyMi7ERS8lkRr0BSRMYJn3tv3ryLtT3\n","To: /content/hacktrain.csv\n","100%|██████████| 1.67M/1.67M [00:00<00:00, 43.7MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1Pd9a30DXPZHgSSzv2y5Hsc44A5oElxKV\n","To: /content/hacktest.csv\n","100%|██████████| 634k/634k [00:00<00:00, 102MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Training data shape: (8000, 27)\n","Test data shape: (2845, 27)\n","Target classes: ['water' 'forest' 'impervious' 'farm' 'grass' 'orchard']\n","\n","=== METHOD 1: Enhanced Preprocessing ===\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","=== METHOD 2: Hyperparameter Tuning ===\n","Fitting 5 folds for each of 60 candidates, totalling 300 fits\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n","200 fits failed out of a total of 300.\n","The score on these train-test partitions for these parameters will be set to nan.\n","If these failures are not expected, you can try to debug them by setting error_score='raise'.\n","\n","Below are more details about the failures:\n","--------------------------------------------------------------------------------\n","100 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n","    return fit_method(estimator, *args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 662, in fit\n","    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n","    return fit_method(estimator, *args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\", line 1267, in fit\n","    multi_class = _check_multi_class(multi_class, solver, len(self.classes_))\n","                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\", line 95, in _check_multi_class\n","    raise ValueError(\"Solver %s does not support a multinomial backend.\" % solver)\n","ValueError: Solver liblinear does not support a multinomial backend.\n","\n","--------------------------------------------------------------------------------\n","50 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n","    return fit_method(estimator, *args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 662, in fit\n","    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n","    return fit_method(estimator, *args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\", line 1193, in fit\n","    solver = _check_solver(self.solver, self.penalty, self.dual)\n","             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\", line 71, in _check_solver\n","    raise ValueError(\n","ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n","\n","--------------------------------------------------------------------------------\n","50 fits failed with the following error:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n","    estimator.fit(X_train, y_train, **fit_params)\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n","    return fit_method(estimator, *args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 662, in fit\n","    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n","    return fit_method(estimator, *args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\", line 1203, in fit\n","    raise ValueError(\"l1_ratio must be specified when penalty is elasticnet.\")\n","ValueError: l1_ratio must be specified when penalty is elasticnet.\n","\n","  warnings.warn(some_fits_failed_message, FitFailedWarning)\n","/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [     nan 0.838875      nan 0.85225       nan      nan      nan 0.838875\n","      nan 0.85225       nan      nan      nan 0.8555        nan 0.853625\n","      nan      nan      nan 0.8555        nan 0.853625      nan      nan\n","      nan 0.853375      nan 0.85275       nan      nan      nan 0.853375\n","      nan 0.85275       nan      nan      nan 0.852125      nan 0.852125\n","      nan      nan      nan 0.852125      nan 0.852125      nan      nan\n","      nan 0.85225       nan 0.85225       nan      nan      nan 0.85225\n","      nan 0.85225       nan      nan]\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Best parameters: {'classifier__C': 0.1, 'classifier__max_iter': 1000, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n","Best cross-validation score: 0.8555\n","\n","=== METHOD 3: Feature Selection ===\n"]},{"output_type":"error","ename":"AttributeError","evalue":"'ColumnTransformer' object has no attribute 'transformers_'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-2151176456>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mk_values\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0mfs_preprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_transformers_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'selector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     fs_pipeline = Pipeline(steps=[\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36mnamed_transformers_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    596\u001b[0m         \"\"\"\n\u001b[1;32m    597\u001b[0m         \u001b[0;31m# Use Bunch object to improve autocomplete\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mBunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrans\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformers_\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_feature_name_out_for_transformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'ColumnTransformer' object has no attribute 'transformers_'"]}]},{"cell_type":"code","source":["from google.colab import files\n","files.download(\"submission.csv\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"CVaoXt8gx_Fm","executionInfo":{"status":"ok","timestamp":1749625077879,"user_tz":-330,"elapsed":42,"user":{"displayName":"Salvin Siju","userId":"12323725506983597856"}},"outputId":"f25d5486-ae1d-4dc7-dab1-0dfd33de1cb7"},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_77528227-1be3-444a-8d2e-dae0f30c2aef\", \"submission.csv\", 33650)"]},"metadata":{}}]}]}